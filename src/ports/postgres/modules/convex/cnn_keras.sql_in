/* ----------------------------------------------------------------------- *//**
 *
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 *
 * @file mlp.sql_in
 *
 * @brief SQL functions for multilayer perceptron
 * @date June 2012
 *
 *
 *//* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4')

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.run_keras(
    source_table text,
    test_table text,
    model_table text,
    n_iter  int
)
RETURNS VOID AS $$
    N_ITERATIONS = n_iter

    import plpy
    import keras
    import numpy as np
    import json
    import pandas as pd
    import time
    import os
    import sys

    from keras.models import Sequential
    from keras.datasets import mnist, cifar10
    from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ZeroPadding2D, Activation
    from keras.optimizers import Adam, SGD
    from keras import backend as keras_backend
    from keras.regularizers import l2 
    from keras.layers import Input
    from keras.applications.imagenet_utils import _obtain_input_shape
    from keras.models import Model

    use_cpu_only=False
    if use_cpu_only:
        import os
        os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # to disable GPU
    else:
        import tensorflow as tf
        config = tf.ConfigProto()
        config.gpu_options.allow_growth = True
        sess = tf.Session(config=config)
        run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)

    n_classes = 10

    def create_model_architecture(n_classes,use_cpu_only):
        model = Sequential()

#        model.add(ZeroPadding2D((1, 1), input_shape=(224,224,3)))
#        model.add(Conv2D(64, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(64, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(128, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(128, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(256, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(256, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(256, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(ZeroPadding2D((1, 1)))
#        model.add(Conv2D(512, (3, 3)))
#        model.add(Activation('relu'))
#        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))
#
#        model.add(Flatten())
#        model.add(Dense(4096))
#        model.add(Activation('relu'))
#        model.add(Dropout(0.5))
#        model.add(Dense(4096))
#        model.add(Activation('relu'))
#        model.add(Dropout(0.5))
#        model.add(Dense(n_classes))
#        model.add(Activation('softmax'))


        # Determine proper input shape
        input_shape = (224,224,3)
        input_shape = _obtain_input_shape(input_shape,
                                      default_size=224,
                                      min_size=48,
                                      data_format=keras_backend.image_data_format(),
                                      require_flatten=True)

        inputs = Input(shape=input_shape)
 
        # Block 1
        x = Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block1_conv1')(inputs)
    
        x = Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block1_conv2')(x)
    
        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name="block1_pool", padding='valid')(x)
    
        # Block 2
        x = Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block2_conv1')(x)
    
        x = Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block2_conv2')(x)
    
        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name="block2_pool", padding='valid')(x)
    
        # Block 3
        x = Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block3_conv1')(x)
    
        x = Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block3_conv2')(x)
    
        x = Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block3_conv3')(x)
    
        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name="block3_pool", padding='valid')(x)
    
        # Block 4
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block4_conv1')(x)
    
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block4_conv2')(x)
    
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block4_conv3')(x)
    
        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name="block4_pool", padding='valid')(x)
    
        # Block 5
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block5_conv1')(x)
    
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block5_conv2')(x)
    
        x = Conv2D(filters=512, kernel_size=3, strides=(1, 1), padding='same',
                   kernel_regularizer=l2(0.0002),
                   activation='relu', name='block5_conv3')(x)
    
        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), name="block5_pool", padding='valid')(x)

        # Classification block
        x = Flatten(name='flatten')(x)
        x = Dense(4096, activation='relu', name='fc1')(x)
        x = Dropout(0.5, name='drop_fc1')(x)

        x = Dense(4096, activation='relu', name='fc2')(x)
        x = Dropout(0.5, name='drop_fc2')(x)
        
        x = Dense(n_classes, activation='softmax', name="predictions")(x)

        model = Model(inputs, x, name='vgg16-places365')


##########
        sgd = SGD(lr=0.01, decay=1e-6, nesterov=True)
        # model.summary()

        parallel_model = model

        if use_cpu_only:
            model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])
        else:
            parallel_model = keras.utils.multi_gpu_model(model, gpus=2)
            parallel_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'],options=run_options)

        return {"model" : model, "parallel_model" : parallel_model}

    with tf.device("/cpu:0"):
        model_template = create_model_architecture(n_classes,use_cpu_only)

    model = model_template["model"]
    parallel_model = model_template["parallel_model"]

    sql_test_x = """
        SELECT x, y FROM {0} limit 2
        """.format(test_table)
    plpy.info('Test sql is : {0}'.format(sql_test_x))
    testData = plpy.execute(sql_test_x)
    plpy.info('finished running select query')


    all_x_test = np.ndarray((0,150528))
    all_y_test = np.ndarray((0))
    for i in range(len(testData)):
        x_test = np.asarray((testData[i]['x'],))
        y_test = np.asarray((testData[i]['y'],))
        #plpy.info('i : {0}'.format(i))
        #plpy.info('X shape : {0}'.format(x_test.shape))
        #plpy.info('Y shape : {0}'.format(y_test.shape))
        all_x_test=np.concatenate((all_x_test, x_test))
        all_y_test=np.concatenate((all_y_test, y_test))

    num_test_examples = all_x_test.shape[0]
    all_x_test = all_x_test.reshape(num_test_examples, 224,224,3)
    all_x_test = all_x_test.astype('float32')
    all_y_test = all_y_test.reshape(num_test_examples)
    plpy.info('X shape : {0}'.format(all_x_test.shape))
    plpy.info('Y shape : {0}'.format(all_y_test.shape))
    all_x_test /= 255.0
    all_y_test = keras.utils.to_categorical(all_y_test,n_classes)

    eval_start = time.time()
    with tf.device("/cpu:0"):
        parallel_model.evaluate(all_x_test, all_y_test, verbose=0)
    eval_time = time.time()
    plpy.info("time to evaluate model = {0}".format(eval_time-eval_start))

    agg_scores = []
    model_arch = model.to_json()
    sql = """
        SELECT MADLIB_SCHEMA.cnn_keras_step(
            x::REAL[],
            y::SMALLINT[],
            gp_segment_id,
            $MAD${0}$MAD$::text,
            $1
        ) AS keras_model
        FROM {1}
        """.format(model_arch, source_table)

    plpy.info("Model arch size: {}KB".format(len(model_arch)/1024))

    update_plan = plpy.prepare(sql, ["bytea"])
    plpy.info("model arch is in place")
    model_string = ''
    start_time = time.time()
    model_shapes = []
    for a in model.get_weights():
        model_string += a.tostring()
        model_string += 'splitter'
        model_shapes.append(a.shape)
    endtime = time.time()
    plpy.info('String dump time : {0} {1}'.format(endtime-start_time, len(filter(None,model_string.split('splitter')))))
    plpy.info("Model state size: {}MB".format(len(model_string)/1024/1024))
    start_time = time.time()
    for i in range(N_ITERATIONS):
        iter_start_time = time.time()
        try:
            model_string = plpy.execute(update_plan, [model_string])[0]['keras_model']
        except plpy.SPIError as e:
            plpy.notice(e)
            plpy.error('plpy exception')
        iter_endtime = time.time()
        plpy.info('Time for iteration {0}:{1}'.format(i, iter_endtime-iter_start_time))
        model_eval = model_template["parallel_model"]
        weightsList = []
        j = 0
        for a in filter(None,model_string.split('splitter')):
            weightsList.append(np.fromstring(a,dtype='float32').reshape(model_shapes[j]))
            j+=1
        model_eval.set_weights(weightsList)
        with tf.device("/cpu:0"):
            agg_score = model_eval.evaluate(all_x_test, all_y_test, verbose=0)[1]
        plpy.info("Training categorical_accuracy in iteration {0} = {1}".format(i, agg_score))
        agg_scores.append(agg_score)

    plan = plpy.prepare("""
        drop table if exists {0};
        CREATE TABLE {0} AS
        SELECT $1 AS keras_model,
        $2 as accuracy_history
        """.format(model_table), ["text", "DOUBLE PRECISION[]"])
    plpy.execute(plan, [weightsList, agg_scores])


$$ language plpythonu;


CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.cnn_keras_transition(
    state               BYTEA,
    ind_var             REAL[],
    dep_var             SMALLINT[],
    seg                 INTEGER,
    architecture        TEXT,
    previous_state      BYTEA
) RETURNS BYTEA AS
$$
import itertools
import numpy as np

import plpy
import keras
import json
import time
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, ZeroPadding2D, Activation
from keras.optimizers import Adam, SGD
from keras.models import model_from_json
from keras import backend as keras_backend

def deserialize(state,model_shapes):
    weightsList = []
    j = 0
    for a in filter(None,state.split('splitter')):
        arr = np.fromstring(a, dtype=np.float32)
        weightsList.append(arr.reshape(model_shapes[j]))
        j+=1

    return weightsList

real_start = time.time()
plpy.info('importing tensorflow from segment')
use_cpu_only=False
if use_cpu_only:
    import os
    os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # to disable GPU
else:
    import tensorflow as tf
    config = tf.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)
    run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)

if not state:
    # model needs to be initialized
    serialized_state = previous_state
else:
    serialized_state = state
keras_model = model_from_json(architecture)
model_shapes = []
for a in keras_model.get_weights():
    model_shapes.append(a.shape)

plpy.info("Transition STARTED")
start = time.time()
weightsList = deserialize(serialized_state,model_shapes)
after_deser = time.time()
keras_model.set_weights(weightsList)
prep_1 = time.time()  # set weights
try:
    if use_cpu_only:
        raise(ValueError)
    parallel_model = keras.utils.multi_gpu_model(keras_model, gpus=(seg%4,seg%4+4))
    plpy.info("Training using GPU's")
except ValueError:
    # This segment doesn't have GPU's enabled
    parallel_model = keras_model
    plpy.info("Training using CPU's only")

prep_2 = time.time()  # multi_gpu_model
# We must run model.compile again, after obtaining the architecutre.
if use_cpu_only:
    keras_model.compile(optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True),
    loss='categorical_crossentropy', metrics=['accuracy'])
else:
    parallel_model.compile(optimizer=SGD(lr=0.01, decay=1e-6, nesterov=True),
        loss='categorical_crossentropy',
        metrics=['accuracy'],options=run_options)
prep_3 = time.time() # compile()
if ind_var == None:
   return None
#plpy.info("buffer len {0} {1}".format(len(ind_var), len(dep_var)))
x_train = np.array(ind_var).reshape(len(ind_var), 224,224,3)
# Figure out why this is necessary, but IT IS necessary!
x_train /= 255.0
y_train = np.array(dep_var)
n_classes = 10
mid = time.time() # convert x,y input to numpy arrays
y_train = keras.utils.to_categorical(y_train,n_classes)

#plpy.info("y train shape is {0}".format(y_train.shape))

plpy.info("Prep times: set weights {}, multi gpu {}, compile {}, x,y to numpy arrays {}".format(prep_1 - after_deser, prep_2 - prep_1, prep_3-prep_2, mid-prep_3))

plpy.info("will try to fit now")
parallel_model.fit(x_train, y_train,
               batch_size=50,
               epochs=1,
               verbose=0)
end = time.time()
plpy.info("done with fit")
model_string = ''
for a in keras_model.get_weights():
    model_string += a.tostring()
    model_string += "splitter"
before_return = time.time()
plpy.info("DeSer ModelArch: {0}, DeSer ModelState: {1}, Prep: {2}, Fit: {3}, Ser ModelState: {4}".format(start-real_start,after_deser-start, mid-after_deser, end-mid, before_return-end))
keras_backend.clear_session()
#plpy.info("TRANSITION done.")
return model_string

$$
LANGUAGE plpythonu
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');


CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.cnn_keras_merge(
    state1          BYTEA,
    state2          BYTEA
) RETURNS BYTEA AS
$$
import json
import numpy as np
import time
import plpy

plpy.info("Starting merge")
merge_start = time.time()

if not state1 or not state2:
    plpy.info("Returning from merge early (only 1 state passed)")
    return state1 or state2

weights1 = [np.fromstring(a,dtype='float32') for a in filter(None,state1.split('splitter'))]
weights2 = [np.fromstring(a,dtype='float32') for a in filter(None,state2.split('splitter'))]

merged_weights = [a+b for a, b in zip(weights1, weights2)]
model_string = ''
for a in merged_weights:
    model_string += a.tostring()
    model_string += "splitter"

merge_finish = time.time()
plpy.info("cnn_keras_merge time = {}".format(merge_finish-merge_start))

return model_string
$$
LANGUAGE plpythonu
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.cnn_keras_final(
    state BYTEA
) RETURNS BYTEA AS
$$
import json
import time
import numpy as np
import plpy

plpy.info("Starting final function")
final_start = time.time()

weights = [np.fromstring(a,dtype='float32') for a in filter(None,state.split('splitter'))]
normalized_weights=[a/1 for a in weights]
model_string = ''
for a in normalized_weights:
    model_string += a.tostring()
    model_string += "splitter"

final_finish = time.time()
plpy.info("cnn_keras_final time = {}".format(final_finish-final_start))
return model_string
$$
LANGUAGE plpythonu
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `NO SQL', `');

DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.cnn_keras_step(REAL[],
                                                      SMALLINT[],
                                                      INTEGER,
                                                      TEXT,
                                                      BYTEA);
CREATE AGGREGATE MADLIB_SCHEMA.cnn_keras_step(
    /* ind_var */             REAL[],
    /* dep_var */             SMALLINT[],
    /* seg */                 INTEGER,
    /* architecture */        TEXT,
    /* previous_state */      BYTEA
)(
    STYPE=BYTEA,
    SFUNC=MADLIB_SCHEMA.cnn_keras_transition,
    PREFUNC=MADLIB_SCHEMA.cnn_keras_merge,
    FINALFUNC=MADLIB_SCHEMA.cnn_keras_final
);
