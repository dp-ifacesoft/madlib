/* ----------------------------------------------------------------------- */
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 *
 * @file minibatch_preprocessing_dl.sql_in
 * @brief TODO
 * @date December 2018
 *
 */
/* ----------------------------------------------------------------------- */

m4_include(`SQLCommon.m4')

/**
@addtogroup grp_minibatch_preprocessing_dl

<div class="toc"><b>Contents</b><ul>
<li class="level1"><a href="#minibatch_preprocessor_dl">Mini-Batch Preprocessor for Deep Learning</a></li>
<li class="level1"><a href="#example">Examples</a></li>
</ul></div>

For Deep Learning based techniques such as Convolutional Neural Nets, the input
data is mostly images. These images can be represented as an array of numbers
where all elements are between 0 and 255 in value. It is standard practice
to divide each of these numbers by 255.0 to normalize the image data.
minibatch_preprocessor() is for general use-cases, but for deep learning based
use-cases we provide minibatch_preprocessor_dl() that is light-weight and is
specific to image datasets. The normalizing constant is parameterized, and can
be specified based on the kind of image data used.
<pre class="syntax">
minibatch_preprocessor_dl(source_table,
                        output_table,
                        dependent_varname,
                        independent_varname,
                        buffer_size,
                        normalizing_const
                        )
</pre>

\b Arguments
<dl class="arglist">
  <dt>source_table</dt>
  <dd>TEXT. Name of the table containing input data.  Can also be a view.
  </dd>

  <dt>output_table</dt>
  <dd>TEXT.  Name of the output table from the preprocessor which
  will be used as input to algorithms that support mini-batching.
  Note that the arrays packed into the output table are randomized
  and normalized (by dividing each element in the independent variable array
  by the normalizing_const), so they will not match up in an obvious way with
  the rows in the source table.
  </dd>

  <dt>dependent_varname</dt>
  <dd>TEXT. Name of the dependent variable column.
  </dd>

  <dt>independent_varname</dt>
  <dd>TEXT. Name of the independent variable column. The column must be of
  a numeric array type.
  </dd>

  <dt>buffer_size (optional)</dt>
  <dd>INTEGER, default: computed.  Buffer size is the
  number of rows from the
  source table that are packed into one row of the preprocessor
  output table.  The default value is computed considering size of
  the source table, number of independent variables, number of groups,
  and number of segments in the database cluster.  For larger data sets,
  the computed buffer size will typically be a value in the millions.
  </dd>

  <dt>normalizing_const (optional)</dt>
  <dd>DOUBLE PRECISION, default: 255.0. The normalizing constant to divide
  each value in the independent_varname array by.
  </dd>
</dl>

<b>Output tables</b>
<br>
    The output table produced by the mini-batch preprocessor contains the following columns:
    <table class="output">
      <tr>
        <th>buffer_id</th>
        <td>INTEGER. Unique id for packed table.
        </td>
      </tr>
      <tr>
        <th>dependent_varname</th>
        <td>ANYARRAY[]. Packed array of dependent variables. The type
        of the array is the same as the type of the dependent variable from
        the source table.
        </td>
      </tr>
      <tr>
        <th>independent_varname</th>
        <td>REAL[]. Packed array of independent variables.
        </td>
      </tr>
    </table>

A summary table named \<output_table\>_summary is also created, which has the following columns:
    <table class="output">
    <tr>
        <th>source_table</th>
        <td>Name of the source table.</td>
    </tr>
    <tr>
        <th>output_table</th>
        <td>Name of output table generated by preprocessor.</td>
    </tr>
    <tr>
        <th>dependent_varname</th>
        <td>Dependent variable from the source table.</td>
    </tr>
    <tr>
        <th>independent_varname</th>
        <td>Independent variable from the source table.</td>
    </tr>
    <tr>
        <th>dependent_vartype</th>
        <td>Type of the dependent varialbe from the source table.</td>
    </tr>
    <tr>
        <th>buffer_size</th>
        <td>Buffer size used in preprocessing step.</td>
    </tr>
   </table>

@anchor example
@par Examples
-#  Create an input data set based on the well known iris data set:
<pre class="example">
DROP TABLE IF EXISTS iris_data;
CREATE TABLE iris_data(
    id serial,
    attributes numeric[],
    class_text varchar,
    class integer,
    state varchar
);
INSERT INTO iris_data(id, attributes, class_text, class, state) VALUES
(1,ARRAY[5.0,3.2,1.2,0.2],'Iris_setosa',1,'Alaska'),
(2,ARRAY[5.5,3.5,1.3,0.2],'Iris_setosa',1,'Alaska'),
(3,ARRAY[4.9,3.1,1.5,0.1],'Iris_setosa',1,'Alaska'),
(4,ARRAY[4.4,3.0,1.3,0.2],'Iris_setosa',1,'Alaska'),
(5,ARRAY[5.1,3.4,1.5,0.2],'Iris_setosa',1,'Alaska'),
(6,ARRAY[5.0,3.5,1.3,0.3],'Iris_setosa',1,'Alaska'),
(7,ARRAY[4.5,2.3,1.3,0.3],'Iris_setosa',1,'Alaska'),
(8,ARRAY[4.4,3.2,1.3,0.2],'Iris_setosa',1,'Alaska'),
(9,ARRAY[5.0,3.5,1.6,0.6],'Iris_setosa',1,'Alaska'),
(10,ARRAY[5.1,3.8,1.9,0.4],'Iris_setosa',1,'Alaska'),
(11,ARRAY[4.8,3.0,1.4,0.3],'Iris_setosa',1,'Alaska'),
(12,ARRAY[5.1,3.8,1.6,0.2],'Iris_setosa',1,'Alaska'),
(13,ARRAY[5.7,2.8,4.5,1.3],'Iris_versicolor',2,'Alaska'),
(14,ARRAY[6.3,3.3,4.7,1.6],'Iris_versicolor',2,'Alaska'),
(15,ARRAY[4.9,2.4,3.3,1.0],'Iris_versicolor',2,'Alaska'),
(16,ARRAY[6.6,2.9,4.6,1.3],'Iris_versicolor',2,'Alaska'),
(17,ARRAY[5.2,2.7,3.9,1.4],'Iris_versicolor',2,'Alaska'),
(18,ARRAY[5.0,2.0,3.5,1.0],'Iris_versicolor',2,'Alaska'),
(19,ARRAY[5.9,3.0,4.2,1.5],'Iris_versicolor',2,'Alaska'),
(20,ARRAY[6.0,2.2,4.0,1.0],'Iris_versicolor',2,'Alaska'),
(21,ARRAY[6.1,2.9,4.7,1.4],'Iris_versicolor',2,'Alaska'),
(22,ARRAY[5.6,2.9,3.6,1.3],'Iris_versicolor',2,'Alaska'),
(23,ARRAY[6.7,3.1,4.4,1.4],'Iris_versicolor',2,'Alaska'),
(24,ARRAY[5.6,3.0,4.5,1.5],'Iris_versicolor',2,'Alaska'),
(25,ARRAY[5.8,2.7,4.1,1.0],'Iris_versicolor',2,'Alaska'),
(26,ARRAY[6.2,2.2,4.5,1.5],'Iris_versicolor',2,'Alaska'),
(27,ARRAY[5.6,2.5,3.9,1.1],'Iris_versicolor',2,'Alaska'),
(28,ARRAY[5.0,3.4,1.5,0.2],'Iris_setosa',1,'Tennessee'),
(29,ARRAY[4.4,2.9,1.4,0.2],'Iris_setosa',1,'Tennessee'),
(30,ARRAY[4.9,3.1,1.5,0.1],'Iris_setosa',1,'Tennessee'),
(31,ARRAY[5.4,3.7,1.5,0.2],'Iris_setosa',1,'Tennessee'),
(32,ARRAY[4.8,3.4,1.6,0.2],'Iris_setosa',1,'Tennessee'),
(33,ARRAY[4.8,3.0,1.4,0.1],'Iris_setosa',1,'Tennessee'),
(34,ARRAY[4.3,3.0,1.1,0.1],'Iris_setosa',1,'Tennessee'),
(35,ARRAY[5.8,4.0,1.2,0.2],'Iris_setosa',1,'Tennessee'),
(36,ARRAY[5.7,4.4,1.5,0.4],'Iris_setosa',1,'Tennessee'),
(37,ARRAY[5.4,3.9,1.3,0.4],'Iris_setosa',1,'Tennessee'),
(38,ARRAY[6.0,2.9,4.5,1.5],'Iris_versicolor',2,'Tennessee'),
(39,ARRAY[5.7,2.6,3.5,1.0],'Iris_versicolor',2,'Tennessee'),
(40,ARRAY[5.5,2.4,3.8,1.1],'Iris_versicolor',2,'Tennessee'),
(41,ARRAY[5.5,2.4,3.7,1.0],'Iris_versicolor',2,'Tennessee'),
(42,ARRAY[5.8,2.7,3.9,1.2],'Iris_versicolor',2,'Tennessee'),
(43,ARRAY[6.0,2.7,5.1,1.6],'Iris_versicolor',2,'Tennessee'),
(44,ARRAY[5.4,3.0,4.5,1.5],'Iris_versicolor',2,'Tennessee'),
(45,ARRAY[6.0,3.4,4.5,1.6],'Iris_versicolor',2,'Tennessee'),
(46,ARRAY[6.7,3.1,4.7,1.5],'Iris_versicolor',2,'Tennessee'),
(47,ARRAY[6.3,2.3,4.4,1.3],'Iris_versicolor',2,'Tennessee'),
(48,ARRAY[5.6,3.0,4.1,1.3],'Iris_versicolor',2,'Tennessee'),
(49,ARRAY[5.5,2.5,4.0,1.3],'Iris_versicolor',2,'Tennessee'),
(50,ARRAY[5.5,2.6,4.4,1.2],'Iris_versicolor',2,'Tennessee'),
(51,ARRAY[6.1,3.0,4.6,1.4],'Iris_versicolor',2,'Tennessee'),
(52,ARRAY[5.8,2.6,4.0,1.2],'Iris_versicolor',2,'Tennessee');
</pre>

-#  Run the preprocessor:
<pre class="example">
DROP TABLE IF EXISTS iris_data_packed, iris_data_packed_summary;
SELECT madlib.minibatch_preprocessor_dl('iris_data',         -- Source table
                                     'iris_data_packed',  -- Output table
                                     'class_text',        -- Dependent variable
                                     'attributes',        -- Independent variables
                                     NULL,                -- buffer size
                                     2                    -- normalizing constant
                                     );
</pre>
For small datasets like in this example, buffer size is mainly
determined by the number of segments in the database.
This example is run on a Greenplum database with 3 segments,
so there are 3 rows with a buffer size of 18.
For PostgresSQL, there would be only one row with a buffer
size of 52 since it is a single node database.
For larger data sets, other factors go into
computing buffers size besides number of segments.
Also, note that the dependent variable has
been one-hot encoded since it is categorical.
Here is a sample of the packed output table:
<pre class="example">
\\x on
SELECT * FROM iris_data_packed;
</pre>
<pre class="result">
-[ RECORD 1 ]-------+-------------------------------------
independent_varname | {{2.55,1.7,0.75,0.1},{2.55,1.9,0.95,0.2},{2.9,1.35,1.95,0.6},{3.35,1.55,2.2,0.7},{2.85,1.3,1.75,0.5},{3.1,1.1,2.25,0.75},...}}
dependent_varname   | {Iris_versicolor,Iris_versicolor,Iris_versicolor,Iris_versicolor,Iris_setosa,Iris_setosa,...}
buffer_id           | 0
-[ RECORD 2 ]-------+-------------------------------------
independent_varname | {{2.4,1.5,0.7,0.15},{2.2,1.6,0.65,0.1},{2.8,1.45,1.8,0.65},{2.9,1.3,2,0.6},{2.2,1.45,0.7,0.1},{2.85,1.4,2.25,0.65},{2.8,1.25,1.95,0.55},...}}
dependent_varname   | {Iris_setosa,Iris_setosa,Iris_versicolor,Iris_versicolor,Iris_setosa,Iris_versicolor,...}
buffer_id           | 1
-[ RECORD 2 ]-------+-------------------------------------
independent_varname | {{2.4,1.7,0.8,0.1},{2.9,1.35,2.05,0.5},{3.15,1.65,2.35,0.8},{2.7,1.95,0.65,0.2},{2.75,1.3,2.2,0.6},{3,1.1,2,0.5},{2.55,1.9,0.8,0.1},...}}
dependent_varname   | {Iris_versicolor,Iris_setosa,Iris_versicolor,Iris_versicolor,Iris_setosa,Iris_setosa,...}
buffer_id           | 2
</pre>
Review the output summary table:
<pre class="example">
\\x on
SELECT * FROM iris_data_packed_summary;
</pre>
<pre class="result">
-[ RECORD 1 ]-------+------------------
source_table        | iris_data
output_table        | iris_data_packed
dependent_varname   | class_text
independent_varname | attributes
dependent_vartype   | character varying
buffer_size         | 18
</pre>

-# Generally the default buffer size will work well,
but if you have occasion to change it:
<pre class="example">
DROP TABLE IF EXISTS iris_data_packed, iris_data_packed_summary;
SELECT madlib.minibatch_preprocessor_dl('iris_data',         -- Source table
                                     'iris_data_packed',  -- Output table
                                     'class_text',        -- Dependent variable
                                     'attributes',        -- Independent variables
                                     10                   -- Buffer size
                                     );
</pre>
Review the number of buffers in the output table:
<pre class="example">
SELECT COUNT(*) FROM iris_data_packed;
</pre>
<pre class="result">
-[ RECORD 1 ]
count | 6
</pre>
Review the output summary table:
<pre class="example">
\\x on
SELECT * FROM iris_data_packed_summary;
</pre>
<pre class="result">
-[ RECORD 1 ]-------+------------------
source_table        | iris_data
output_table        | iris_data_packed
dependent_varname   | class_text
independent_varname | attributes
dependent_vartype   | character varying
buffer_size         | 10
</pre>

*/

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.minibatch_preprocessor_dl(
    source_table                VARCHAR,
    output_table                VARCHAR,
    dependent_varname           VARCHAR,
    independent_varname         VARCHAR,
    buffer_size                 INTEGER,
    normalizing_const           DOUBLE PRECISION
) RETURNS VOID AS $$
    PythonFunctionBodyOnly(utilities, minibatch_preprocessing)
    from utilities.control import MinWarning
    with AOControl(False):
        with MinWarning('error'):
            minibatch_preprocessor_obj = minibatch_preprocessing.MiniBatchPreProcessorDL(**globals())
            minibatch_preprocessor_obj.minibatch_preprocessor_dl()
$$ LANGUAGE plpythonu VOLATILE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `MODIFIES SQL DATA', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.minibatch_preprocessor_dl(
    source_table            VARCHAR,
    output_table            VARCHAR,
    dependent_varname       VARCHAR,
    independent_varname     VARCHAR,
    buffer_size             INTEGER
) RETURNS VOID AS $$
  SELECT MADLIB_SCHEMA.minibatch_preprocessor_dl($1, $2, $3, $4, $5, 255.0);
$$ LANGUAGE sql VOLATILE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `MODIFIES SQL DATA', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.minibatch_preprocessor_dl(
    source_table            VARCHAR,
    output_table            VARCHAR,
    dependent_varname       VARCHAR,
    independent_varname     VARCHAR
) RETURNS VOID AS $$
  SELECT MADLIB_SCHEMA.minibatch_preprocessor_dl($1, $2, $3, $4, NULL, 255.0);
$$ LANGUAGE sql VOLATILE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `MODIFIES SQL DATA', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.minibatch_preprocessor_dl(
    message VARCHAR
) RETURNS VARCHAR AS $$
    PythonFunctionBodyOnly(utilities, minibatch_preprocessing)
    return minibatch_preprocessing.MiniBatchDocumentation.minibatch_preprocessor_dl_help(schema_madlib, message)
$$ LANGUAGE plpythonu VOLATILE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `MODIFIES SQL DATA', `');

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.minibatch_preprocessor_dl()
RETURNS VARCHAR AS $$
    PythonFunctionBodyOnly(utilities, minibatch_preprocessing)
    return minibatch_preprocessing.MiniBatchDocumentation.minibatch_preprocessor_dl_help(schema_madlib, '')
$$ LANGUAGE plpythonu VOLATILE
m4_ifdef(`__HAS_FUNCTION_PROPERTIES__', `MODIFIES SQL DATA', `');


CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.agg_array_concat_transition(anyarray, anyarray)
  RETURNS anyarray
   AS 'select $1 || $2'
   LANGUAGE SQL
   IMMUTABLE;

CREATE OR REPLACE FUNCTION MADLIB_SCHEMA.agg_array_concat_merge(anyarray, anyarray)
  RETURNS anyarray
   AS 'select $1 || $2'
   LANGUAGE SQL
   IMMUTABLE
   RETURNS NULL ON NULL INPUT;

DROP AGGREGATE IF EXISTS MADLIB_SCHEMA.agg_array_concat(anyarray);
CREATE AGGREGATE MADLIB_SCHEMA.agg_array_concat(anyarray) (
   SFUNC = MADLIB_SCHEMA.agg_array_concat_transition,
   STYPE = anyarray,
   PREFUNC = MADLIB_SCHEMA.agg_array_concat_merge
   );
